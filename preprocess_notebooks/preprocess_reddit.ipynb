{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/common/reddit/id2name.json', 'r') as file:\n",
    "    id2name = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsplits = ['test', 'valid', 'train']\n",
    "\n",
    "split_dfs = []\n",
    "for dsplit in dsplits:\n",
    "    split_df = pd.read_csv(f'../data/common/reddit/{dsplit}.csv')\n",
    "    split_dfs.append(split_df)\n",
    "\n",
    "df = pd.concat(split_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract movie names\n",
    "def extract_movie_names(row):\n",
    "    ids = re.findall(r\"tt\\d+\", row)  \n",
    "    movie_names = [id2name[i] for i in ids if i in id2name]  \n",
    "    movie_names = list(set(movie_names))\n",
    "    return movie_names\n",
    "\n",
    "df['extracted_names'] = df['processed'].apply(extract_movie_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove downvoted \n",
    "df2 = df[df['upvotes'].fillna(1) >= 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['utc_time'] = pd.to_datetime(df2['utc_time'], unit='s').dt.tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowledge cutoff 2022, 2023\n",
    "mask = ~df2['utc_time'].dt.year.isin([2022, 2023])\n",
    "df2 = df2[mask]\n",
    "\n",
    "# remove comments without movie mentions\n",
    "mask = df2['is_seeker'] | df2['extracted_names'].apply(lambda x: len(x) > 0)\n",
    "df2 = df2[mask]\n",
    "\n",
    "# request must be about movies\n",
    "mask = df2['processed'].astype(str).str.contains('movie|Movie|film|Film')\n",
    "df2 = df2[mask]\n",
    "\n",
    "# written by seeker but actually it's a comment\n",
    "mask = ~(df2['is_seeker'] & (df2['turn_order'] != 0))\n",
    "df2 = df2[mask]\n",
    "\n",
    "# consider only head comments\n",
    "mask = (df2['turn_order'] < 2)\n",
    "df2 = df2[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['sub_id'] = df2['conv_id'].str.rsplit('_', n=1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(set(df2['sub_id']))} submissions, {len(set(df2['conv_id']))} utterances\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = list(set(df2[df2['is_seeker'] & (df2['turn_order'] == 0)]['raw']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare requests data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_df = df2[df2['is_seeker'] & (df2['turn_order'] == 0)]\n",
    "req_df['request'] = req_df['raw'].str.split(r\"'USER',\\s*\").str[-1].str.rsplit(r'\\\\n\\\\n', n=1).str[0]\n",
    "\n",
    "requests_df = pd.DataFrame({\n",
    "    'sub_id': req_df['sub_id'],\n",
    "    'request': req_df['request'],\n",
    "    'movies_str': req_df['extracted_names']\n",
    "})\n",
    "requests_df = requests_df.drop_duplicates(subset=['sub_id'], keep='first')\n",
    "requests_df['movies_str'] = requests_df['movies_str'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(requests_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(f'../data/t4_requests/')\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "requests_df.to_csv(save_dir / f'processed_requests.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request2comment_ids = {}\n",
    "\n",
    "for _, group in df2.groupby('sub_id'):\n",
    "    \n",
    "    seeker_rows = group[group['is_seeker'] == True]\n",
    "    \n",
    "    if not seeker_rows.empty:    \n",
    "        request_id = seeker_rows.iloc[0]['turn_id']\n",
    "        comment_ids = group['turn_id'].tolist()\n",
    "        \n",
    "        comment_ids = [x for x in comment_ids if x != request_id]\n",
    "        \n",
    "        if len(comment_ids) >= 1:  # at least one comment\n",
    "            request2comment_ids[request_id] = comment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(request2comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2movies = {}  # extracted_names \n",
    "id2context = {}  # raw\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    \n",
    "    turn_id = row['turn_id']\n",
    "    \n",
    "    raw = row['raw']\n",
    "    id2context[turn_id] = ast.literal_eval(raw)[1].strip()\n",
    "    \n",
    "    if not row['is_seeker']:\n",
    "        id2movies[turn_id] = row['extracted_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### true vs random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comment_ids = set()\n",
    "for comment_ids in request2comment_ids.values():\n",
    "    all_comment_ids.update(comment_ids)\n",
    "\n",
    "all_movies = set()\n",
    "for movies in id2movies.values():\n",
    "    all_movies.update(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_data = []\n",
    "context_data = []\n",
    "\n",
    "for request_id, comment_ids in tqdm(request2comment_ids.items()):\n",
    "    \n",
    "    # request\n",
    "    request = id2context[request_id]\n",
    "\n",
    "    # positive comment (first comment)\n",
    "    first_comment_id = comment_ids[0]\n",
    "    first_comment = id2context[first_comment_id]\n",
    "    \n",
    "    # random comment\n",
    "    rand_comment_id = random.choice(list(all_comment_ids - set(comment_ids)))\n",
    "    random_comment = id2context[rand_comment_id]\n",
    "\n",
    "    # positive movies  \n",
    "    first_movies = id2movies[first_comment_id]\n",
    "    assert(len(first_movies) >= 1)\n",
    "    \n",
    "    # random movies (same amount)\n",
    "    all_positive_movies = []\n",
    "    for comment_id in comment_ids:\n",
    "        all_positive_movies+= id2movies[comment_id]\n",
    "        \n",
    "    random_movies = random.sample(list(all_movies - set(all_positive_movies)), k=len(first_movies))\n",
    "    \n",
    "    items_data.append(\n",
    "        {\n",
    "            \"request_id\": request_id,\n",
    "            \"request\": request,\n",
    "            \"first\": ', '.join(first_movies),\n",
    "            \"random\": ', '.join(random_movies)\n",
    "        }\n",
    "    )\n",
    "    context_data.append(\n",
    "        {\n",
    "            \"request_id\": request_id,\n",
    "            \"request\": request,\n",
    "            \"first\": first_comment,\n",
    "            \"random\": random_comment\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_large_df = pd.DataFrame(items_data)\n",
    "context_large_df = pd.DataFrame(context_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_large_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_large_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = items_large_df[items_large_df['request'].str.contains('request', case=False, na=False)]\n",
    "context_df = context_large_df[context_large_df['request'].str.contains('request', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(items_df), len(context_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(f'../data/t5_feedback/')\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "items_large_df.to_csv(save_dir / f'items-large.csv', index=False)\n",
    "items_df.to_csv(save_dir / f'items.csv', index=False)\n",
    "\n",
    "context_large_df.to_csv(save_dir / f'context-large.csv', index=False)\n",
    "context_df.to_csv(save_dir / f'context.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
